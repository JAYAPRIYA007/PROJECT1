#Input is combination of Languages, Writers, Composers, MusicGenre and Duration
#First 4 Input Layer Neurons represent Songs of First Language, First Writer, First Composer, First MusicGenre, [3/4/5/6] Minute Duration Song.\n')

library(stringi)

cat('Decsription Types Encoded:\n')
cat('--------------------\n')
##0000 00001 00001 00001 00001 is first song type  -Duration 3 minutes
#Tamil Languages's Vairamuthus' Ilayaraja's Pop's 3Minute Duration Song
#0000 00001 00001 00001 00010 is second song type - Duration 4 minutes
#Tamil Languages's Vairamuthus' Ilayaraja's Pop's 4Minute Duration Song
typeleng<-4
typeleng2<-5
typeleng3<-5
typeleng4<-5
typeleng5<-5
counter<-0
#dfsongtype<-data.frame(songindex=numeric(0),songcodedvalue=character(0))
MatSongTypes<-matrix(nrow=2500,ncol=2)

GetSongTypes<-function()
{
for (j in 1:1)
{
  for (i in 1:typeleng)
  {
    leng<-typeleng-i+1
    strtmp1<-stri_pad(1, leng, pad = "0") 
    if(typeleng-leng>0)
    {
      strtmp1<-paste( strtmp1,stri_pad(0,typeleng-leng ,pad="0"),sep='')
      #strtmp <- sprintf('%20d',i)
    }
    
    for (k in 1:typeleng2)
    {
      leng<-typeleng2-k+1
      strtmp2<-stri_pad(1, leng, pad = "0") 
      if(typeleng2-leng>0)
      {
        strtmp2<-paste( strtmp2,stri_pad(0,typeleng2-leng ,pad="0"),sep='')
        #strtmp <- sprintf('%20d',i)
      }
      #print((strtmp2))
      #strtemp <-paste(strtmp1,strtmp2,sep='')
      #print((strtemp))
  
    
    for (k in 1:typeleng3)
    {
      leng<-typeleng3-k+1
      strtmp3<-stri_pad(1, leng, pad = "0") 
      if(typeleng3-leng>0)
      {
        strtmp3<-paste( strtmp3,stri_pad(0,typeleng3-leng ,pad="0"),sep='')
        #strtmp <- sprintf('%20d',i)
      }
      #print((strtmp2))
      #strtemp <-paste(strtmp1,strtmp2,strtmp3,sep='')
      #print((strtemp))
  
    for (k in 1:typeleng4)
    {
      leng<-typeleng4-k+1
      strtmp4<-stri_pad(1, leng, pad = "0") 
      if(typeleng4-leng>0)
      {
        strtmp4<-paste( strtmp4,stri_pad(0,typeleng4-leng ,pad="0"),sep='')
        #strtmp <- sprintf('%20d',i)
      }
      #print((strtmp2))
      #strtemp <-paste(strtmp1,strtmp2,strtmp3,strtmp4,sep='')
      #print((strtemp))
   
    for (k in 1:typeleng5)
    {
      leng<-typeleng5-k+1
      strtmp5<-stri_pad(1, leng, pad = "0") 
      if(typeleng5-leng>0)
      {
        strtmp5<-paste( strtmp5,stri_pad(0,typeleng5-leng ,pad="0"),sep='')
        #strtmp <- sprintf('%20d',i)
      }
      #print((strtmp2))
      strtemp <-paste(strtmp1,strtmp2,strtmp3,strtmp4,strtmp5,sep='')
      print((strtemp))
      counter<<-counter+1
      MatSongTypes[counter,1]<<-counter
      MatSongTypes[counter,2]<<-strtemp
    }
  }
    }
    }
  }
}
}
GetSongTypes()

print(MatSongTypes)


cat('--------------------\n')
cat('Music Feature Component:\n')


  #Refer DeepNeuralNetwork-Important-Code_McCaffreyTestRun0817 folder for these commented lines. Tutorial - https://msdn.microsoft.com/en-us/magazine/mt493293.aspx
  #cat("Creating a 2-(4-2-2)-3 deep neural network ");
  #int numInput = 2;
  #int[] numHidden = new int[] { 4,2,2 }; // 3 hidden layers implied
   numInput =2500
   inputlayercount=numInput
   #int[] numHidden = new int[] { 500, 64 }; // 3 hidden layers implied
   hiddenlayer1count<-500
   hiddenlayer2count<-64
   outputlayercount<-32
   #To store which song type (input neuron) will fall into which characteristics (output neuron)
   MatCharacteristics<-matrix(nrow=numInput,ncol=2)   
   numHidden<-c(hiddenlayer1count,hiddenlayer2count)
  #int numOutput = 3;
   numOutput = outputlayercount #output layer
    nInput=numInput  # number input nodes
    nHidden<-numHidden #c()  # number hidden nodes, each layer
     nOutput<-numOutput# 0  # number output nodes
    nLayers<- length(numHidden)  #0  # number hidden node layers
   iNodes<- replicate(numInput,0) #c()  # input nodes
   hNodes<-matrix(nrow=hiddenlayer1count,ncol=hiddenlayer2count)
   oNodes<- replicate(numOutput,0) #c();
   #public double[][] ihWeights;  # input- 1st hidden
    ihWeights<-matrix(nrow=numInput,ncol=hiddenlayer1count)
   #public double[][][] hhWeights; # hidden-hidden
     n<-nLayers-1
     m = hiddenlayer1count
     k = hiddenlayer2count
     hhWeights<-list()
     #hhWeights<-replicate(2,0) #NA,matrix(nrow=2,ncol=2),matrix(nrow=2,ncol=2)) #c(matrix(nrow=500,ncol=64),matrix(nrow=64,ncol=32))
     
    hhWeights[[1]]<-matrix(nrow=hiddenlayer1count,ncol=hiddenlayer2count)#   <-    array(NA, c(m,k,n))
    hhWeights[[2]]<-matrix(nrow=hiddenlayer2count,ncol=outputlayercount)
    
   #public double[][] hoWeights;  #last hidden-output
   hoWeights<-matrix(  nrow=hiddenlayer2count,ncol=numOutput)
   
   #public double[][] hBiases;  // hidden node biases
   hBiases<-matrix(nrow=hiddenlayer1count,ncol=hiddenlayer2count)
   #public double[] oBiases;  // output node biases
   oBiases<-replicate(numOutput,0) #c()
   
   #rnd = new Random(0);  // seed could be a ctor parameter
   
   nInput <- numInput
   nHidden <- replicate(length(numHidden),0) #new int[numHidden.Length];
   for(i in 1:length(numHidden))
   {
     nHidden[i]<-numHidden[i]
   }
   #for (int i = 0; i < numHidden.Length; ++i)
  #   this.nHidden[i] = numHidden[i];
   nOutput <- numOutput
   nLayers <- length(numHidden)#.Length;
   
   iNodes <-replicate(numInput,0) #new double[numInput];
   
   
   #hNodes = MakeJaggedMatrix(numHidden);
   # n = 1000
   # m=1000
   # k = 10;
   # hNodes<-array(NA, c(n,m,k))
   #oNodes <-replicate(numOutput,0) #new double[numOutput];
   #ihWeights  <- matrix (nrow=numInput,ncol=numHidden[1]) #MakeMatrix(numInput, numHidden[0]);
   #hoWeights <-matrix(nrow=64,ncol=32)# rows=numHidden[nLayers] ,cols=numOutput) #MakeMatrix(numHidden[nLayers - 1], numOutput);
   #dim(hoWeights)
   #hhWeights = new double[nLayers - 1][][];  #// if 3 h layer, 2 h-h weights[][]
   # n = numHidden[1]
   # m=numHidden[2]
   # k =2# nLayers;
   # hhWeights<-    array(NA, c(k,n,m))
   # hhWeights[1] <- matrix(nrow=500,ncol=64)
   # hhWeights[2] <- matrix(nrow=64,ncol=32)
   # dim(hhWeights)
   #hBiases = MakeJaggedMatrix(numHidden);  // pass an array of lengths
   # n = numHidden[1]
   # m=numHidden[2]
   # k = nLayers;
   #   hBiases<-matrix(nrow=500,ncol=64)#    array(NA, c(k,n,m))
   # 
   # #oBiases = new double[numOutput];
   # oBiases<-replicate(numOutput,0)
 # DeepNet dn = new DeepNet(numInput, numHidden, numOutput);
  
   
   
   
   
   #CONSTRUCTOR LOGIC ENDS
   
   #--------------------------------------
   #NUM WEIGHTS FUNCTION LOGIC
   #nw = DeepNet.NumWeights(numInput, numHidden, numOutput)
   
   #// total num weights and biases
   #int ihWts = numInput * numHidden[0];
   ihWts <- numInput * numHidden[1]
   
   #int hhWts = 0;
   hhWts <-0
   numHiddenlengthminusone<-length(numHidden)-1
   for(j in 1:numHiddenlengthminusone)
   {
     rows =numHidden[j]
     cols =numHidden[j+1]
     hhWts<- hhWts+(rows*cols)
   }
   
   # for (int j = 0; j < numHidden.Length - 1; ++j)
   # {
   #   int rows = numHidden[j];
   #   int cols = numHidden[j + 1];
   #   hhWts += rows * cols;
   # }
   
   #int hoWts = numHidden[numHidden.Length - 1] * numOutput;
   hoWts <- numHidden[length(numHidden)]* numOutput
   
   
   #int hbs = 0;
   hbs <-0
   
   for(i in 1:length(numHidden))
   {
     hbs <- hbs + numHidden[i] 
   }
   
   #for (int i = 0; i < numHidden.Length; ++i)
  #   hbs += numHidden[i];
   
   
   #int obs = numOutput;
   obs <- numOutput
   
   #int nw = ihWts + hhWts + hoWts + hbs + obs;
   nw <- ihWts + hhWts + hoWts + hbs + obs
   
   
   #return nw;
   
   #NUM WEIGHTS FUNCTION LOGIC ENDS
   
  
  #Console.WriteLine("Setting weights and biases to 0.01 to " + (nw / 100.0).ToString("F2"));
  #cat("Setting weights and biases");
  
  
  wts<-replicate(nw,0)
  #double[] wts = new double[nw];
  wtslen<-length(wts)
  for(i in 1:wtslen)
  {
   
    wts[i]<-(i*0.00001)
  
    
  }
  
  
  #SETWEIGHTS FUNCTION LOGIC STARTS
  #dn.SetWeights(wts)
  ptr <- 1
  for(i in 1:nInput)
  {
    #nrow(hNodes[1])
    
    for(j in 1:numHidden[1])
    {
      ihWeights[i,j]<-wts[ptr]
      ptr<-ptr+1
    }
  }
  
  #for (int i = 0; i < nInput; ++i)  // input node
  #for (int j = 0; j < hNodes[0].Length; ++j)  // 1st hidden layer nodes
  #ihWeights[i][j] = wts[ptr++];
  
  
  for(h in 1:1)
  {
    for (j in 1 :nHidden[1])
    {
     for (jj in 1 :nHidden[2]) 
     {
       hhWeights[[h]][j,jj]<-wts[ptr]
       ptr<-ptr+1
     }
    }
  }

  
  #dim(hhWeights)
  # 
  # for (int h = 0; h < nLayers - 1; ++h)  // not last h layer
  # {
  #   for (int j = 0; j < nHidden[h]; ++j)  // from node
  #   {
  #     for (int jj = 0; jj < nHidden[h + 1]; ++jj)  // to node
  #     {
  #       hhWeights[h][j][jj] = wts[ptr++];
  #     }
  #   }
  # }
  
  #int hi = this.nLayers - 1;  // if 3 hidden layers (0,1,2) last is 3-1 = [2]
  hi <-  nLayers - 1
  for(j in 1:nHidden[hi+1])
  {
    for (k in 1 :nOutput)
    {
      
      hoWeights[j,k] <- wts[ptr]
      ptr<-ptr+1
    }
  }
  dim(hoWeights)
  # for (int j = 0; j < this.nHidden[hi]; ++j)
  # {
  #   for (int k = 0; k < this.nOutput; ++k)
  #   {
  #     hoWeights[j][k] = wts[ptr++];
  #   }
  # }
  
  hBiases<-matrix(0,nrow=2,ncol =nHidden[1])
  
  for(h in 1:nLayers)
  {
    for(j in 1:nHidden[h])
    {
      hBiases[h,j] <-0.0
  
    }
  }
  
  for(h in 1:nLayers)
  {
    for(j in 1:nHidden[h])
    {
      hBiases[h,j] <-0# wts[ptr]
      ptr<-ptr+1
    }
  }
    dim(hBiases)
  # 
  # for (int h = 0; h < nLayers; ++h)  // hidden node biases
  # {
  #   for (int j = 0; j < this.nHidden[h]; ++j)
  #   {
  #     hBiases[h][j] = wts[ptr++];
  #   }
  # }
  
  for(k in 1:nOutput)
  {
    oBiases[k] <-0# wts[ptr]
    ptr<-ptr+1
  }
  # for (int k = 0; k < nOutput; ++k)
  # {
  #   oBiases[k] = wts[ptr++];
  # }
  # 
  #SETWEIGHTS FUNCTION LOGIC ENDS
  
  
  
  #//Console.WriteLine("\nComputing output values for input = [1.0, 2.0] \n");
  cat('\nComputing output values for input.\n')
  
  #//double[] xValues = new double[] { 1.0, 2.0 };
  
  #double[] xValues = new double[numInput];// { 1.0, 2.0 };
  xValues<-replicate(numInput,0)
  
  for(i1 in 1:numInput) #(int i1 = 1; i1 <= numInput; i1++)
  {
    xValues[i1] <- i1
  }
  #dn.ComputeOutputs(xValues)
  #COMPUTE OUTPUTS FUNCTION LOGIC STARTS
  # 'xValues' might have class label or not
  # copy vals into iNodes
  for (i in 1:nInput)  #possible trunc
  {
   
    if(i==nInput)
    {
    iNodes[i] <-xValues[i]
    }
    else
    {
      iNodes[i] <-xValues[i]
    }
    
  }
  # zero-out all hNodes, oNodes
  hNodes<-matrix(0,nrow=2,ncol =nHidden[1])
  for(h in 1:nLayers)
  {
    for (j in 1:nHidden[h])
    {
      hNodes[h,j] <-0.0
    }
  }
  dim(hNodes)
  for (k in 1:nOutput)
  {
    oNodes[k] <- 0.0
  }
  # input to 1st hid layer
  for(j in 1:nHidden[1])# each hidden node, 1st layer
  {
    print(j)
  }
  options(scipen=999)
  for(j in 1:nHidden[1])# each hidden node, 1st layer
  {
   
    hNodes[1,j]<-0.0
    for (i in 1:nInput)
    {
    
      if(i==1)
      {
      hNodes[1,j] <-  hNodes[1,j] +  (ihWeights[i,j] * iNodes[i])
      }
      else
      {
        ihWeights[i,j] <-0
        hNodes[1,j] <-  hNodes[1,j] +  (ihWeights[i,j] * iNodes[i])
      }
    }
    #add the bias
    hNodes[1,j] <-  (hNodes[1,j]+  hBiases[1,j]);
    # apply activation
    #hNodes[1,j] <- tanh(hNodes[1,j] )
  }
  
  # each remaining hidden node

  for(h in 2:nLayers)
  {
   
    for (j in 1:nHidden[h])
    {
      for(jj in 1:nHidden[h-1])
      {
        hNodes[h,j] <-  hNodes[h,j]+  hhWeights[[h - 1]][jj,j] * hNodes[h - 1,jj];
      }
      hNodes[h,j] <-hNodes[h,j]+ hBiases[h,j];  # add bias value
      #hNodes[h,j] <- tanh(hNodes[h,j]);  #apply activation
      #print(hNodes[h,j])
    }
  }

  
  # compute ouput node values
  for (k in 1:nOutput)
  {
    oNodes[k]<-0.0
    for (j in 1:nHidden[nLayers])
    {
      
      oNodes[k]<-  oNodes[k] + (hoWeights[j,k] * hNodes[nLayers ,j])
    }
      oNodes[k] <- oNodes[k]+ oBiases[k]#  // add bias value
      cat('Pre-softmax output node [' , k , '] value = ' , oNodes[k],'\n');
    
      
    
    
  }
  #COMPUTE OUTPUTS FUNCTION LOGIC ENDS HERE
  hoWeights[1,1] 
  hNodes[nLayers ,1]
  # softmax activation all oNodes
  #SOFTMAX FUNCTION LOGIC STARTS HERE
   max1 <- oNodes[1]
   oNodeslength<-length(oNodes)
   for(i in 1:oNodeslength)
   {
     if (oNodes[i] > max1) 
     {
       max1 <- oNodes[i]
     }
   }
  
  
  # determine scaling factor -- sum of exp(each val - max)
   scale <- 0.0
   for(i in 1:oNodeslength)
   {
     scale <- scale + exp(oNodes[i]-max1)
   }
  
   
   result <-replicate(oNodeslength,0) 
   for(i in 1:oNodeslength)
   {
     result[i] <- exp(oNodes[i] - max1)  /scale
   }
  
   #SOFTMAX FUNCTION LOGIC ENDS HERE
  retResult <- result
  #double[] retResult = Softmax(oNodes); 
  
  for(k in 1 :nOutput)
  {
    oNodes[k] <- retResult[k]
  }
  
  for(i in 1:numOutput)
  {
    cat('Output Layer ' , i , ':', oNodes[i],'\n')
  }
  cat(retResult)# calling convenience
  #COMPUTE OUTPUTS FUNCTION LOGIC ENDS
  
  segments<-round(numInput/numOutput)
  for(i in 1:numInput)
  {
    
    value <-floor(i /segments)+1
    if (value>=numOutput)
    {
      value<-numOutput
    }
    MatCharacteristics[ i,1 ] <-i
    MatCharacteristics[ i,2 ] <-oNodes[value]
    
  }
  
  
  #END OF MUSIC CHARACTERISTICS EXTRACTION
  
  cat('Languages List:\n')
  Languages<-c('Tamil','English','Telugu','Malayalam','Hindi')
  cat(Languages)
  cat('\n-------------------\n')
  cat('Writers List:\n')
  Writers<-c('Vairamuthu','Muthukumar','Thamarai','Pa.Vijay','Kannan')
  cat(Writers)
  cat('\n-------------------\n')
  cat('Composers List:\n')
  Composers<-c('Ilayaraja','A.R.Rahman','G.V.Prakash','Deva','Harris Jayaraj')
  cat(Composers)
  cat('\n-------------------\n')
  cat('Genre List:\n')
  Genres<-c('Pop','Rock','Jazz','Folk','HipHop')
  cat(Genres)
  cat('\n-------------------\n')
  cat('Duration List\n')
  Duration<-c('3','4','5','6')
  cat(Duration)
  cat('\n-------------------\n')
  #4*5*5*5*5
  #So input layers count is  4*5*5*5*5 = 2500
  #0000 00001 00001 00001 00001 is first song type  -Duration 3 minutes
  #Tamil Languages's Vairamuthus' Ilayaraja's Pop's 3Minute Duration Song
  
  #0000 00001 00001 00001 00010 is second song type - Duration 4 minutes
  #Tamil Languages's Vairamuthus' Ilayaraja's Pop's 4Minute Duration Song
  
  cat('First 4 Input Layer Neurons represent Songs of First Language, First Writer, First Composer, First MusicGenre, [3/4/5/6] Minute Duration Song.\n')
  
  
  Mat<-matrix(nrow=10,ncol=2)
  for(i in 1:10)
  {
  Mat[i,1]<-paste('User',i,sep='')
  Mat[i,2]<- as.integer( runif(1) * inputlayercount)
  }
  cat('User\tSongTypeInterested:\tSongCode(D4,G5,C5,W5,L5)\tSongCharacteristic\n')
  cat('-------------------------\n')
  Matcount<-nrow(Mat)
  for(i in 1:Matcount)
  {
    cat(Mat[i,1] ,'\t',Mat[i,2],'\t',MatSongTypes[i,2],'\t', MatCharacteristics[as.integer( Mat[i,2]),2],'\n')
  }
  MatMusicFeatureCharacteristics<-MatCharacteristics
  #---------------------------------------------------------------------
  
  
  
  #MatCharacteristics[20,2]
  
  #BELOW LINES ARE NOT NECESSARY INSTEAD OF COMMENT - IF CONDITION IS WRITTEN SO THAT CODE WILL NOT WORK
  if(FALSE)
  {
  #DUMP FUNCTION LOGIC STARTS
  for(i in 1:nInput)
  
  {
    cat('input node [' , i , '] = ' , iNodes[i],'\n');
  }
  for(h in 1:nLayers) #(int h = 0; h < nLayers; ++h)
  {
    cat('\n');
    for (j in 1:nHidden[h]) #(int j = 0; j < nHidden[h]; ++j)
    {
      cat('hidden layer ' , h , ' node [' , j , '] = ' , hNodes[h,j],'\n');
    }
  }
  cat('\n')
  for(k in 1:nOutput)# (int k = 0; k < nOutput; ++k)
  {
    cat('output node [' , k , '] = ' , oNodes[k],'\n');
  }
  
  if (showWeights == false)
    return #// bail out
  
  cat('\n')
  for (i in 1:nInput)#(int i = 0; i < nInput; ++i)
  {
    for (j in 1:nHidden[1]) #(int j = 0; j < nHidden[0]; ++j)
    {
      cat('input-hidden wt [' , i , '][' , j , '] = ' , ihWeights[i,j],'\n');
    }
  }
  
  for(h in 1:nLayers-1) # (int h = 0; h < nLayers - 1; ++h)  // note
  {
  cat('\n')
    for(j in 1 :nHidde[h])# (int j = 0; j < nHidden[h]; ++j)
    {
      for (jj in 1: nHidden[h+1]) #(int jj = 0; jj < nHidden[h + 1]; ++jj)
      {
        cat('hidden-hidden wt layer ' , h , ' to layer ' , (h + 1) , ' node [' , j , '] to [' , jj , '] = ' , hhWeights[h,j,jj],'\n');
      }
    }
  }
  
  cat('\n')
  for(j in 1:nHidden[nLayers - 1]) #(int j = 0; j < nHidden[nLayers - 1]; ++j)
  {
    for(k in 1 :nOutput)# (int k = 0; k < nOutput; ++k)
    {
     cat('hidden-output wt [' , j , '][' , k , '] = ' , hoWeights[j,k],'\n');
    }
  }
  
  for (h in 1 :nLayers) #(int h = 0; h < nLayers; ++h)
  {
    cat('\n')
    for (j in 1 :nHidden[h]) #(int j = 0; j < nHidden[h]; ++j)
    {
      cat('hidden layer ' , h , ' bias [' , j , '] = ' , hBiases[h,j],'\n');
    }
  }
  
  cat('\n')
  for (k in 1:nOutput) #(int k = 0; k < nOutput; ++k)
  {
    cat('output node bias [' , k , '] = ' , oBiases[k],'\n')
  }
  #DUMP FUNCTION LOGIC ENDS
  cat("\nEnd demo \n");
  
}

